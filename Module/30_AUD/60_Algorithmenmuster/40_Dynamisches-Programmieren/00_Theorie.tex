\documentclass{bschlangaul-theorie}
\bLadePakete{syntax,mathe}

\begin{document}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Theorie-Teil
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\chapter{Dynamische Programmierung}

\begin{bQuellen}
\item \cite[Seite 10-12]{aud:fs:3}
\item \cite[Seite 230-235 (PDF 248-253)]{saake}
\item \cite{wiki:dynamische-programmierung}
\end{bQuellen}

\noindent
Dynamische Programmierung ist eine Methode zum algorithmischen Lösen
eines Optimierungsproblems durch \bEmph{Aufteilung in Teilprobleme} und
\bEmph{systematische Speicherung} von Zwischenresultaten.
\footcite{wiki:dynamische-programmierung}

Dynamische Programmierung \bEmph{vereint Aspekte} der drei bisher
vorgestellten \bEmph{Algorithmenmuster}. Vom Ansatz der
\bEmph{Greedy}-Algorithmen wird die \bEmph{Wahl optimaler Teillösungen}
übernommen, von \bEmph{Divide-and-conquer} und \bEmph{Backtracking} die
\bEmph{rekursive Herangehensweise} basierend auf einem
Konfigurationsbaum. Während Divide-and-conquer-Verfahren unabhängige
Teilprobleme durch rekursive Aufrufe lösen, werden bei der dynamischen
Programmierung abhängige Teilprobleme optimiert gelöst, indem mehrfach
auftretende Teilprobleme nur einmal gelöst werden.
\footcite[Seite 230 (PDF 248)]{saake}

Als Vorteil der dynamischen Programmierung kann eine \bEmph{Verbesserung
der Laufzeit-Effizienz} genannt werden. Es wird jedoch mehr
\bEmph{Speicherplatz} benötigt.
\footcite{aud:fs:3}

%-----------------------------------------------------------------------
%
%-----------------------------------------------------------------------

\section{Das Rucksack-Problem\footcite[Seite 231-235]{saake}}

\bJavaDatei{muster/rucksack/Rucksack}

\literatur

\end{document}
